{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48624c2f-1a58-4805-b31f-d6a92b196b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e46d576-c34c-4500-af16-2f9a82e0008c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Email</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Labels                                              Email Unnamed: 2  \\\n",
       "0       0  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1       0                      Ok lar... Joking wif u oni...        NaN   \n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3       0  U dun say so early hor... U c already then say...        NaN   \n",
       "4       0  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"dataset.csv\"\n",
    "data = pd.read_csv(PATH, encoding='latin-1')\n",
    "\n",
    "data = data.rename(columns={\"v1\": \"Labels\", \"v2\": \"Email\"})\n",
    "data['Labels'] = data['Labels'].apply(lambda x: 0 if x == \"ham\" else 1)\n",
    "\n",
    "# 0 : No Spam\n",
    "# 1: spam\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e13e3eb3-d42e-47c4-aa00-141ddb78c2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Email</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Labels                                              Email Unnamed: 2  \\\n",
       "0       0  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1       0                      Ok lar... Joking wif u oni...        NaN   \n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3       0  U dun say so early hor... U c already then say...        NaN   \n",
       "4       0  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc55ec1f-ae36-48a6-b2e8-a7ad414f56f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6b94262-c962-499b-800c-3c6207b3bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem.porter import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a648da9f-7d22-46ae-8f4f-33bacd713fd2",
   "metadata": {},
   "source": [
    "## Apply the pre processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7015a14c-f730-49c4-ab57-925c1f26ba64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Himanshu\n",
      "[nltk_data]     Singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Apply the pre processing steps\n",
    "stemmer = PorterStemmer()\n",
    "corpus = []\n",
    "sp_words = set(stopwords.words('english'))\n",
    "nltk.download('stopwords')\n",
    "for i in range(len(data)):\n",
    "    emails = data['Email'].iloc[i].lower()\n",
    "    emails = emails.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    emails = [stemmer.stem(word) for word in emails if word not in sp_words]\n",
    "    emails = ' '.join(emails)\n",
    "    corpus.append(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0728df9b-4fac-4b9e-99c3-9fb22e0a81b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('go jurong point crazi avail bugi n great world la e buffet cine got amor wat',\n",
       " 76,\n",
       " 'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       " 111)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0], len(corpus[0]), data['Email'].iloc[0], len(data['Email'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c7df53-be6c-49dd-a2df-ec32a53728e1",
   "metadata": {},
   "source": [
    "## # Vectorize this corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94a71293-ac10-40f6-8b50-a44223a39ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize this corpus\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus).toarray()\n",
    "Y = data['Labels']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5664e708-89fc-4d9b-920a-8660434e26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a213c4-8b99-409c-86a9-eb9c236ec155",
   "metadata": {},
   "source": [
    "## # To run this Model on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e531a3aa-214a-4efd-972e-8ca96b428069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run this Model on GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'CPU')\n",
    "X_train = torch.tensor(X_train).type(torch.float).to(device)\n",
    "X_test = torch.tensor(X_test).type(torch.float).to(device)\n",
    "Y_train = torch.tensor(np.array(Y_train)).type(torch.float).to(device)\n",
    "Y_test = torch.tensor(np.array(Y_test)).type(torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3efa4951-608c-4b81-bf44-7681ac329da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size,\n",
       " torch.Size([1115, 8038]),\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For debugging\n",
    "type(X_train[1].shape), X_test.shape, X_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666f365d-a8e8-4e61-9026-5c2e786f2d69",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5936d078-60d4-4ddf-90ee-cf278960b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_features):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = nn.Linear(input_features, 1)\n",
    "    def forward(self, X):\n",
    "        return torch.sigmoid(self.model(X))\n",
    "\n",
    "# Initialize the model\n",
    "torch.manual_seed(42)\n",
    "input_features = X_train.shape[1]\n",
    "model = MyModel(input_features).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf29a701-3b44-401a-b794-bdc678fed6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "loss_fn = nn.BCELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d744997c-8d29-4da6-9be2-cf2db82f95e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "from torchmetrics import Accuracy\n",
    "acc = Accuracy(task=\"binary\", num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4150e29-6b39-403d-b0c2-f86409b0d0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/6000], Loss: 0.4231\n",
      "Epoch [200/6000], Loss: 0.2959\n",
      "Epoch [300/6000], Loss: 0.2243\n",
      "Epoch [400/6000], Loss: 0.1783\n",
      "Epoch [500/6000], Loss: 0.1464\n",
      "Epoch [600/6000], Loss: 0.1230\n",
      "Epoch [700/6000], Loss: 0.1052\n",
      "Epoch [800/6000], Loss: 0.0913\n",
      "Epoch [900/6000], Loss: 0.0801\n",
      "Epoch [1000/6000], Loss: 0.0710\n",
      "Epoch [1100/6000], Loss: 0.0634\n",
      "Epoch [1200/6000], Loss: 0.0570\n",
      "Epoch [1300/6000], Loss: 0.0516\n",
      "Epoch [1400/6000], Loss: 0.0469\n",
      "Epoch [1500/6000], Loss: 0.0428\n",
      "Epoch [1600/6000], Loss: 0.0392\n",
      "Epoch [1700/6000], Loss: 0.0361\n",
      "Epoch [1800/6000], Loss: 0.0333\n",
      "Epoch [1900/6000], Loss: 0.0308\n",
      "Epoch [2000/6000], Loss: 0.0286\n",
      "Epoch [2100/6000], Loss: 0.0266\n",
      "Epoch [2200/6000], Loss: 0.0248\n",
      "Epoch [2300/6000], Loss: 0.0231\n",
      "Epoch [2400/6000], Loss: 0.0216\n",
      "Epoch [2500/6000], Loss: 0.0203\n",
      "Epoch [2600/6000], Loss: 0.0190\n",
      "Epoch [2700/6000], Loss: 0.0179\n",
      "Epoch [2800/6000], Loss: 0.0168\n",
      "Epoch [2900/6000], Loss: 0.0158\n",
      "Epoch [3000/6000], Loss: 0.0149\n",
      "Epoch [3100/6000], Loss: 0.0141\n",
      "Epoch [3200/6000], Loss: 0.0133\n",
      "Epoch [3300/6000], Loss: 0.0125\n",
      "Epoch [3400/6000], Loss: 0.0119\n",
      "Epoch [3500/6000], Loss: 0.0112\n",
      "Epoch [3600/6000], Loss: 0.0106\n",
      "Epoch [3700/6000], Loss: 0.0101\n",
      "Epoch [3800/6000], Loss: 0.0095\n",
      "Epoch [3900/6000], Loss: 0.0091\n",
      "Epoch [4000/6000], Loss: 0.0086\n",
      "Epoch [4100/6000], Loss: 0.0082\n",
      "Epoch [4200/6000], Loss: 0.0077\n",
      "Epoch [4300/6000], Loss: 0.0074\n",
      "Epoch [4400/6000], Loss: 0.0070\n",
      "Epoch [4500/6000], Loss: 0.0067\n",
      "Epoch [4600/6000], Loss: 0.0063\n",
      "Epoch [4700/6000], Loss: 0.0060\n",
      "Epoch [4800/6000], Loss: 0.0057\n",
      "Epoch [4900/6000], Loss: 0.0055\n",
      "Epoch [5000/6000], Loss: 0.0052\n",
      "Epoch [5100/6000], Loss: 0.0050\n",
      "Epoch [5200/6000], Loss: 0.0047\n",
      "Epoch [5300/6000], Loss: 0.0045\n",
      "Epoch [5400/6000], Loss: 0.0043\n",
      "Epoch [5500/6000], Loss: 0.0041\n",
      "Epoch [5600/6000], Loss: 0.0039\n",
      "Epoch [5700/6000], Loss: 0.0037\n",
      "Epoch [5800/6000], Loss: 0.0036\n",
      "Epoch [5900/6000], Loss: 0.0034\n",
      "Epoch [6000/6000], Loss: 0.0032\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 6000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    y_pred = model(X_train).squeeze()\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = loss_fn(y_pred, Y_train)\n",
    "    \n",
    "    # Zero gradients, backward pass, optimizer step\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bb7b8a9-1826-4504-816e-3fc1dc4e57fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.03%\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test).squeeze()\n",
    "    y_test_pred = y_test_pred.round()  # Convert probabilities to binary predictions\n",
    "\n",
    "    # Move tensor to CPU before converting to numpy\n",
    "    y_test_pred_cpu = y_test_pred.cpu().numpy()\n",
    "\n",
    "    # Assuming Y_test is also a PyTorch tensor, move it to CPU and convert to numpy\n",
    "    Y_test_cpu = Y_test.cpu().numpy()\n",
    "\n",
    "    # Calculate accuracy using numpy arrays\n",
    "    accuracy = (y_test_pred_cpu == Y_test_cpu).mean()\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d35df6-225d-4fe7-bf88-d75f31a84811",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1d6f34d-4cc8-4c67-96f1-5bdeb712d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save model using PyTorch's save method\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# Save the vectorizer using pickle\n",
    "with open('count_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f3d5ee5-38da-4675-89ef-37caba3a9f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36m                                                       Spam or Not Spam Detector 🌟\u001b[0m\n",
      "\u001b[35m                                                   ====================================\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[33m\n",
      "Enter the email text to check: \u001b[0m Subject: Lose 20 pounds in 2 weeks! Body: Try our miracle weight loss pills now! Click here for a special discount.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      "✅ Provided Email is Not Spam!\u001b[0m\n",
      "\u001b[32mYour inbox is safe! 😊\u001b[0m\n",
      "\n",
      "Thank you for using the Spam Detector! 🚀 😊\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[33m\n",
      "Do you want to check another email? (y/n): \u001b[0m y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36m                                                       Spam or Not Spam Detector 🌟\u001b[0m\n",
      "\u001b[35m                                                   ====================================\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[33m\n",
      "Enter the email text to check: \u001b[0m  Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      "✅ Provided Email is Not Spam!\u001b[0m\n",
      "\u001b[32mYour inbox is safe! 😊\u001b[0m\n",
      "\n",
      "Thank you for using the Spam Detector! 🚀 😊\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[33m\n",
      "Do you want to check another email? (y/n): \u001b[0m y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36m                                                       Spam or Not Spam Detector 🌟\u001b[0m\n",
      "\u001b[35m                                                   ====================================\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[33m\n",
      "Enter the email text to check: \u001b[0m  Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam Spam\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      "✅ Provided Email is Not Spam!\u001b[0m\n",
      "\u001b[32mYour inbox is safe! 😊\u001b[0m\n",
      "\n",
      "Thank you for using the Spam Detector! 🚀 😊\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[33m\n",
      "Do you want to check another email? (y/n): \u001b[0m n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\n",
      "Exiting the Spam Detector. Goodbye! 👋\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from termcolor import colored\n",
    "import emoji\n",
    "\n",
    "while True:\n",
    "    print(colored(\"                                                       Spam or Not Spam Detector 🌟\", 'cyan', attrs=['bold']))\n",
    "    print(colored(\"                                                   ====================================\", 'magenta'))\n",
    "\n",
    "    # Get user input (email text)\n",
    "    message = input(colored(\"\\nEnter the email text to check: \", 'yellow'))\n",
    "\n",
    "    # Preprocess the message\n",
    "    message = message.lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    message = [stemmer.stem(word) for word in message if word not in sp_words]\n",
    "    message = ' '.join(message)\n",
    "\n",
    "    # Transform the message into the same format as your training data\n",
    "    message = [message]\n",
    "    X_message = vectorizer.transform(message)\n",
    "\n",
    "    # Convert the sparse matrix to a dense matrix and then to a PyTorch tensor\n",
    "    X_message = torch.tensor(X_message.toarray(), dtype=torch.float).to(device)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Make predictions\n",
    "        y_test_pred = model(X_message).squeeze()\n",
    "        y_test_pred = (y_test_pred >= 0.5).float()  # Convert probabilities to binary predictions\n",
    "\n",
    "    # Decorative Output based on Prediction\n",
    "    if y_test_pred.item() == 1:  # .item() converts tensor to a Python scalar\n",
    "        print(colored(\"\\n🚨 Provided Email is Spam! 🚨\", 'red', attrs=['bold']))\n",
    "        print(colored(\"We detected potentially harmful content! ⚠️\", 'red'))\n",
    "    else:\n",
    "        print(colored(\"\\n✅ Provided Email is Not Spam!\", 'green', attrs=['bold']))\n",
    "        print(colored(\"Your inbox is safe! 😊\", 'green'))\n",
    "\n",
    "    # Additional Fun Emojis for Enhanced User Experience\n",
    "    print(\"\\nThank you for using the Spam Detector! 🚀 😊\")\n",
    "\n",
    "    # Ask user if they want to continue or exit\n",
    "    user_choice = input(colored(\"\\nDo you want to check another email? (y/n): \", 'yellow')).lower()\n",
    "    if user_choice != 'y':\n",
    "        print(colored(\"\\nExiting the Spam Detector. Goodbye! 👋\", 'cyan'))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b94afebb-cb7a-4612-b42f-7bfc19db98ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "True Labels: [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions:\", y_test_pred_cpu[:50])\n",
    "print(\"True Labels:\", Y_test_cpu[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca8ae81-55bd-460f-ac24-fcf360246996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
